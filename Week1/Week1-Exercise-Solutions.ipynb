{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6ac4438",
   "metadata": {},
   "source": [
    "# Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33fa5ae1",
   "metadata": {},
   "source": [
    "Just using beautiful soup go to the description of this course and extract the number of SCQF level for it. http://www.drps.ed.ac.uk/21-22/dpt/cxcmse11427.htm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f331c68d",
   "metadata": {},
   "source": [
    "Spoiler alert: the content should be 'SCQF Level ...'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9403c7e",
   "metadata": {},
   "source": [
    "*hint*: you can use in to check for occurance of a word in a sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8db806c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this sentence has a word banana in it\n"
     ]
    }
   ],
   "source": [
    "if 'banana' in 'a sentence with bananas':\n",
    "    print('this sentence has a word banana in it')\n",
    "\n",
    "# if word in sentence:\n",
    "#     print('this sentence has a word in it')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f65ecb1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# !pip install bs4 \n",
    "from urllib.request import urlopen\n",
    "import os\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02d2f136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCQF Level 11 (Postgraduate)\n"
     ]
    }
   ],
   "source": [
    "# website address\n",
    "page = 'http://www.drps.ed.ac.uk/21-22/dpt/cxcmse11427.htm'\n",
    "\n",
    "# open the url and store the website\n",
    "website = urlopen(page)\n",
    "\n",
    "# convert the website's content, for this a parser is needed. In this case a html parser\n",
    "soup = BeautifulSoup(website, 'html.parser')\n",
    "\n",
    "# Retrieve the cell that contains 'SCQF Level'\n",
    "# Retrieve the cell that contains 'SCQF Credits'\n",
    "table = soup.find('table', {'class':'sitstablegrid'})\n",
    "for cell in table.findChildren('td'):\n",
    "    if 'SCQF Level' in cell.text:\n",
    "        print(cell.text)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d55313f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5065b76f",
   "metadata": {},
   "source": [
    "# Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0391b1cc",
   "metadata": {},
   "source": [
    "Retrieve all the scores of the iPhone 12 on https://www.carphonewarehouse.com/:\n",
    "* Search the code for the location of the score (Hint: right click -> inspect when you click on the score)\n",
    "* You might have to streamline the scrolling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7fcccb",
   "metadata": {},
   "source": [
    "**IMPORTANT NOTE**: This will only work on your own machine (not via noteable, I think). Also: You'll need to unzip the chrome driver in the folder where your notebook is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "378d951c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install selenium\n",
    "\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48c573e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define method that will create a browser, suitable to your operating system\n",
    "import sys\n",
    "def get_a_browser():\n",
    "    if sys.platform.startswith('win32') or sys.platform.startswith('cygwin'):\n",
    "        return webdriver.Chrome() # windows\n",
    "    else:\n",
    "        return webdriver.Chrome('./chromedriver') # mac"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182857f5",
   "metadata": {},
   "source": [
    "Please fill in all '......' in the code block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76729b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<selenium.webdriver.remote.webelement.WebElement (session=\"bc607e873676e69924d81b590dfa9736\", element=\"3c5dc2db-570d-4c4b-a324-9e178a203fcf\")>\n",
      "Review Title:     Excellent phone   \n",
      "Review Title:     Not as Clever   \n",
      "Review Title:     good phone   \n",
      "Review Title:     Wheres the plug!!!   \n",
      "\n",
      "Page:  0\n",
      "Review Title:     Easy to hold   \n",
      "Review Title:     Nice Phone   \n",
      "\n",
      "Page:  1\n",
      "No next button\n"
     ]
    }
   ],
   "source": [
    "browser = get_a_browser()\n",
    "\n",
    "# the url we want to open\n",
    "# fill in the correct url for the iPhone X\n",
    "url = u'https://www.carphonewarehouse.com/apple/iphone-12.html#!colour=red&capacity=64GB&dealType=pm'\n",
    "\n",
    "# the browser will start and load the webpage\n",
    "browser.get(url)\n",
    "\n",
    "# we wait 1 second to let the page load everything\n",
    "time.sleep(1)\n",
    "\n",
    "# we load the HTML body (the main page content without headers, footers, etc.)\n",
    "body = browser.find_element(By.TAG_NAME,'body')\n",
    "\n",
    "# we use seleniums' send_keys() function to physically scroll down where we want to click\n",
    "body.send_keys(Keys.PAGE_DOWN)\n",
    "body.send_keys(Keys.PAGE_DOWN)\n",
    "\n",
    "time.sleep(1)\n",
    "\n",
    "# accept cookies:\n",
    "accept_cookies = browser.find_element(By.ID,\"onetrust-accept-btn-handler\")\n",
    "print(accept_cookies)\n",
    "accept_cookies.click();\n",
    "time.sleep(1)\n",
    "\n",
    "\n",
    "# we search for an element that is called 'customer reviews', which is a button\n",
    "# the button can be clicked with the .click() function\n",
    "\n",
    "browser.find_element(By.LINK_TEXT, \"Reviews\").click();\n",
    "\n",
    "\n",
    "# we need to scroll further down to collect the reviews and especially click the next button\n",
    "body.send_keys(Keys.PAGE_DOWN)\n",
    "\n",
    "# sleep again, let everything load\n",
    "time.sleep(2)\n",
    "\n",
    "\n",
    "def find_review_titles_in_source(html_source):\n",
    "    # see beautifulsoup\n",
    "    soup = BeautifulSoup(html_source, 'html.parser')\n",
    "    # find all the elements of class pros and print them\n",
    "#     titles = soup.find_all('h3', attrs={'class': 'bv-content-title'})\n",
    "    titles = soup.find_all('h3', attrs={'class': 'bv-content-title', 'itemprop':'headline'})\n",
    "    for title in titles:\n",
    "        print(\"Review Title: \"+title.text)  \n",
    "\n",
    "find_review_titles_in_source(browser.page_source)      \n",
    "        \n",
    "# loop the following 10 times\n",
    "for which_page in range(10):\n",
    "    print('\\nPage: ', which_page)\n",
    "    # search for the next button to access the next reviews\n",
    "    try:\n",
    "        next_button = browser.find_element(By.CSS_SELECTOR,\n",
    "                                           '.bv-content-btn.bv-content-btn-pages.bv-content-btn-pages-last.bv-focusable.bv-content-btn-pages-active')\n",
    "#                                            '.bv-content-btn-pages-last.bv-content-btn-pages-active')\n",
    "        next_button.click()\n",
    "    except NoSuchElementException:  #spelling error making this code not work as expected\n",
    "        print(\"No next button\")\n",
    "        break\n",
    "    # scroll down to get the reviews\n",
    "    body.send_keys(Keys.PAGE_DOWN)\n",
    "    time.sleep(1)\n",
    "    # get the page content for beautiful soup\n",
    "    find_review_titles_in_source(browser.page_source)      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d941229",
   "metadata": {},
   "source": [
    "# Exercise 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2051d948",
   "metadata": {},
   "source": [
    "Apply the same code you used before to retrieve all Tweets of President Biden, Barack Obama, or any Tweeter you like"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33bdf98b",
   "metadata": {},
   "source": [
    "* Find the number of retweets\n",
    "* Write the scores to a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25026ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d44e7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define method that will create a browser, suitable to your operating system\n",
    "import sys\n",
    "def get_a_browser():\n",
    "    if sys.platform.startswith('win32') or sys.platform.startswith('cygwin'):\n",
    "        return webdriver.Chrome() # windows\n",
    "    else:\n",
    "        return webdriver.Chrome('./chromedriver') # mac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68355c42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retweets: 2.5K\n",
      "Retweets: 5.6K\n",
      "Retweets: 3.9K\n",
      "Retweets: 1.1K\n",
      "Retweets: 3.3K\n",
      "Retweets: 12.1K\n",
      "Retweets: 2.5K\n",
      "Retweets: 3.6K\n",
      "Retweets: 4K\n",
      "Retweets: 2.8K\n",
      "Retweets: 6.4K\n",
      "Retweets: 1.7K\n",
      "Retweets: 4.3K\n",
      "Retweets: 705\n",
      "Retweets: 5.8K\n",
      "Retweets: 2.7K\n"
     ]
    }
   ],
   "source": [
    "# launch the browser\n",
    "browser = get_a_browser()\n",
    "\n",
    "# launch the page you want to look at\n",
    "twitter_url = u'https://twitter.com/POTUS'\n",
    "\n",
    "# Add the search term\n",
    "query = ''\n",
    "\n",
    "# Create the url\n",
    "url = twitter_url+query\n",
    "\n",
    "# Get the page\n",
    "browser.get(url)\n",
    "\n",
    "# Let the Tweets load\n",
    "time.sleep(1)\n",
    "\n",
    "# Find the body of the page\n",
    "body = browser.find_element(By.TAG_NAME,'body')\n",
    "\n",
    "# Keep scrolling down using a simulation of the PAGE_DOWN button\n",
    "for _ in range(10):\n",
    "    body.send_keys(Keys.PAGE_DOWN)\n",
    "    time.sleep(1)\n",
    "\n",
    "# Get the tweets by their class (similar to Beautifulsoup's find({'class':'something'}))\n",
    "scores = browser.find_elements(By.XPATH,\"//div[@data-testid='retweet']\");\n",
    "    \n",
    "# Write them to csv file\n",
    "output_file = open('twitter_scores.csv','w')\n",
    "\n",
    "# Print Tweets\n",
    "for score in scores:\n",
    "    if score.text!= \"\":\n",
    "        print('Retweets: '+ score.text)\n",
    "        output_file.write(str(score.text)+\"\\n\")\n",
    "\n",
    "output_file.close()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c908af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
